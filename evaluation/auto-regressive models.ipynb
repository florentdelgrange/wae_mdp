{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfpl = tfp.layers\n",
    "tfkl = tfk.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 16:53:19.339436: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "latent_space_size = 12\n",
    "\n",
    "cond = tf.random.uniform(shape=(batch_size, 32))\n",
    "\n",
    "autoregressive_net = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    event_shape=[latent_space_size],\n",
    "    hidden_units=[128, 128],\n",
    "    activation='relu',\n",
    "    conditional=True,\n",
    "    conditional_event_shape=tf.shape(cond)[1: ])\n",
    "\n",
    "distribution = tfd.Autoregressive(\n",
    "    distribution_fn=lambda x: tfd.RelaxedBernoulli(\n",
    "        logits=tf.unstack(autoregressive_net(x, conditional_input=cond), axis=-1)[0],\n",
    "        temperature=1./2.),\n",
    "    sample0=tf.zeros([batch_size, latent_space_size]),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-step Markov chain estimation\n",
    "$s_0 -> \\frac{1}{2}:  s_1 + \\frac{1}{4}: s_2 + \\frac{1}{4}: s_3$\n",
    "\n",
    "$s_0$ is initial (label $00$), $s_1$ is safe ($10$), and $s_2, s_3$ are unsafe ($01$), i.e.,\\\n",
    "$s_0$: $000$, \\\n",
    "$s_1$: $100$, \\\n",
    "$s_2$: $010$, \\\n",
    "$s_3$: $011$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 16:41:48.541693: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "states = tf.constant([[0., 0., 0.], [1., 0., 0.], [0., 1., 0.], [0., 1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(102400, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = 1024 * 100\n",
    "\n",
    "dataset = tf.stack([\n",
    "    # toss a coin, if heads then s_0 goes to s_1\n",
    "    states[1] if random.random() <= 0.5 else\n",
    "    # else (if tails), then toss the coin again; if heads, then s_0 goes to s_2\n",
    "    (states[2] if random.random() <= 0.5 else\n",
    "    # otherwise, s_0 goes to s_3\n",
    "    states[3]) for _ in range(dataset_size)\n",
    "    ])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.4988086 , 0.5011914 , 0.25016603], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(dataset, axis=0) / dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "12800/12800 [==============================] - 20s 2ms/step - loss: 1.9626\n",
      "Epoch 2/4\n",
      "12800/12800 [==============================] - 19s 1ms/step - loss: 1.9603\n",
      "Epoch 3/4\n",
      "12800/12800 [==============================] - 18s 1ms/step - loss: 1.9605\n",
      "Epoch 4/4\n",
      "12800/12800 [==============================] - 29s 2ms/step - loss: 1.9610\n",
      "Bernoulli probs [[0.55006218 0.44993785 0.244285166]]\n",
      "P(s_1 | s_0) = [0.228655428]\n",
      "P(s_2 | s_0) = [0.15299]\n",
      "P(s_3 | s_0) = [0.0494540781]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "event_shape = (3, )\n",
    "\n",
    "\"\"\"\n",
    "x = tfk.Input(shape=(3, ))\n",
    "model = tfk.Model(\n",
    "    [x],\n",
    "    tfd.Independent(\n",
    "        tfd.Bernoulli(logits=logits),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    ).log_prob(x))\n",
    "\"\"\"\n",
    "\n",
    "model = tfk.Sequential([\n",
    "    tfkl.Dense(tfpl.IndependentBernoulli.params_size(event_shape)),\n",
    "    tfpl.IndependentBernoulli(event_shape),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss= lambda y, model: -model.log_prob(y))\n",
    "                     \n",
    "model.fit(\n",
    "    x=tf.zeros(shape=(dataset_size, 1)),  # always provide the same input\n",
    "    y=dataset,\n",
    "    batch_size=batch_size,\n",
    "    epochs=4,\n",
    "    steps_per_epoch=dataset_size // batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=True)\n",
    "\n",
    "bernoulli = model(tf.zeros(shape=(1, 1)))\n",
    "tf.print(\"Bernoulli probs\", bernoulli.mean())\n",
    "tf.print(\"P(s_1 | s_0) =\", tf.exp(bernoulli.log_prob(states[1])))\n",
    "tf.print(\"P(s_2 | s_0) =\", tf.exp(bernoulli.log_prob(states[2])))\n",
    "tf.print(\"P(s_3 | s_0) =\", tf.exp(bernoulli.log_prob(states[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "12800/12800 [==============================] - 30s 2ms/step - loss: 1.0437\n",
      "Epoch 2/4\n",
      "12800/12800 [==============================] - 29s 2ms/step - loss: 1.0415\n",
      "Epoch 3/4\n",
      "12800/12800 [==============================] - 23s 2ms/step - loss: 1.0413\n",
      "Epoch 4/4\n",
      "12800/12800 [==============================] - 22s 2ms/step - loss: 1.0413\n",
      "P(s_1 | s_0) = 0.477598876\n",
      "P(s_2 | s_0) = 0.242849588\n",
      "P(s_3 | s_0) = 0.279551566\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "event_shape = (3, )\n",
    "\n",
    "autoregressor = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    event_shape=event_shape,\n",
    "    hidden_units=[64, 64],\n",
    "    activation='relu')\n",
    "\n",
    "distribution = tfd.Autoregressive(\n",
    "    lambda x: tfd.Independent(\n",
    "        tfd.Bernoulli(logits=tf.unstack(autoregressor(x), axis=-1)[0]),\n",
    "        reinterpreted_batch_ndims=1),\n",
    "    sample0=tf.zeros(event_shape))\n",
    "\n",
    "x = tfk.Input(shape=event_shape)\n",
    "log_prob = distribution.log_prob(x)\n",
    "model = tfk.Model(x, log_prob)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=1e-2),\n",
    "    loss= lambda _, log_prob: -log_prob)\n",
    "\n",
    "model.fit(\n",
    "    x=dataset,\n",
    "    y=tf.zeros(shape=(dataset_size, )), # log_prob = 0 <=> prob = 1\n",
    "    batch_size=batch_size,\n",
    "    epochs=4,\n",
    "    steps_per_epoch=dataset_size // batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=True)\n",
    "\n",
    "tf.print(\"P(s_1 | s_0) =\", distribution.prob(states[1]))\n",
    "tf.print(\"P(s_2 | s_0) =\", distribution.prob(states[2]))\n",
    "tf.print(\"P(s_3 | s_0) =\", distribution.prob(states[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With a MaskedAutoregressiveFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.int32, name=None), inferred_value=[3], name='tf.math.reduce_prod_3/Prod:0', description=\"created by layer 'tf.math.reduce_prod_3'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/03/wm8m8y9d50b1rxl0lpvj0dn40000gn/T/ipykernel_31013/3552858957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \"\"\"\n\u001b[0;32m-> 1316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36m_call_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_and_control_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_log_prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/distributions/transformed_distribution.py\u001b[0m in \u001b[0;36m_log_prob\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;31m# For caching to work, it is imperative that the bijector is the first to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;31m# modify the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbijector_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m     event_ndims = tf.nest.map_structure(\n\u001b[1;32m    363\u001b[0m         \u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_from_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/invert.py\u001b[0m in \u001b[0;36minverse\u001b[0;34m(self, y, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minverse_log_det_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m       \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimplemented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36m_call_forward\u001b[0;34m(self, x, name, **kwargs)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_injective\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No caching for non-injective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'forward'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/internal/cache_util.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbijector\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcached\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/internal/cache_util.py\u001b[0m in \u001b[0;36m_lookup\u001b[0;34m(self, input, forward_name, inverse_name, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m       output = nest.map_structure(\n\u001b[1;32m    492\u001b[0m           \u001b[0m_containerize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m           self._invoke(input, forward_name, kwargs, attrs))\n\u001b[0m\u001b[1;32m    494\u001b[0m       output_ref = WeakStructRef(\n\u001b[1;32m    495\u001b[0m           \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/internal/cache_util.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, fn_name, kwargs, attributes)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_invoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;34m\"\"\"Invokes the wrapped function. Override to customize behavior.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbijector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow_probability/python/bijectors/masked_autoregressive.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_loop_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         maximum_iterations=event_size)\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 620\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2556\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2558\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m       maximum_iterations = ops.convert_to_tensor(\n\u001b[0;32m-> 2763\u001b[0;31m           maximum_iterations, name=\"maximum_iterations\")\n\u001b[0m\u001b[1;32m   2764\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    345\u001b[0m                                          as_ref=False):\n\u001b[1;32m    346\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf2.7/lib/python3.7/site-packages/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError(\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;34mf'You are passing {self}, an intermediate Keras symbolic input/output, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;34m'to a TF API that does not allow registering custom dispatchers, such '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;34m'as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.int32, name=None), inferred_value=[3], name='tf.math.reduce_prod_3/Prod:0', description=\"created by layer 'tf.math.reduce_prod_3'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output."
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "event_shape = (3, )\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    hidden_units=[64, 64],\n",
    "    activation='relu')\n",
    "\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=tfd.Sample(\n",
    "        tfd.Independent(\n",
    "            tfd.Bernoulli(logits=tf.zeros(shape=event_shape, dtype=tf.float32), dtype=tf.float32),\n",
    "            reinterpreted_batch_ndims=1),),\n",
    "    bijector=tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "        lambda y: (made(y)[..., 0], None),\n",
    "        is_constant_jacobian=False)))\n",
    "distribution._made = made\n",
    "\n",
    "\n",
    "x = tfk.Input(shape=event_shape)\n",
    "log_prob = distribution.log_prob(x)\n",
    "model = tfk.Model(x, log_prob)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=1e-2),\n",
    "    loss= lambda _, log_prob: -log_prob)\n",
    "\n",
    "model.fit(\n",
    "    x=dataset,\n",
    "    y=tf.zeros(shape=(dataset_size, )), # log_prob = 0 <=> prob = 1\n",
    "    batch_size=batch_size,\n",
    "    epochs=4,\n",
    "    steps_per_epoch=dataset_size // batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=True)\n",
    "\n",
    "bernoulli = distribution\n",
    "tf.print(\"P(s_1 | s_0) =\", distribution.prob(states[1]))\n",
    "tf.print(\"P(s_2 | s_0) =\", distribution.prob(states[2]))\n",
    "tf.print(\"P(s_3 | s_0) =\", distribution.prob(states[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[0.        , 1.        , 1.0385809 ],\n",
       "       [0.        , 1.        , 1.0385809 ],\n",
       "       [1.        , 0.03900308, 0.09938622],\n",
       "       [0.        , 1.        , 0.03858088],\n",
       "       [0.        , 1.        , 0.03858088],\n",
       "       [1.        , 0.03900308, 1.0993862 ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    hidden_units=[128, 128],\n",
    "    # event_shape=event_shape,\n",
    "    activation='relu',\n",
    "    name=\"InvertMaskedAutoregressorNetwork\")\n",
    "\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=tfd.Sample(\n",
    "        tfd.Independent(\n",
    "            tfd.Bernoulli(logits=tf.zeros(shape=event_shape, dtype=tf.float32), dtype=tf.float32),\n",
    "            reinterpreted_batch_ndims=1),),\n",
    "    bijector=tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "        lambda y: (made(y)[..., 0], None),\n",
    "        is_constant_jacobian=True)))\n",
    "distribution._made = made\n",
    "\n",
    "print(distribution._made.weights)\n",
    "distribution.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[0.07339588, 0.9487939 , 0.9456719 ],\n",
       "       [0.7476593 , 0.00531152, 0.97534597],\n",
       "       [0.8681984 , 0.3399576 , 0.95810634],\n",
       "       [0.27695602, 0.9912412 , 0.96136844],\n",
       "       [0.93835366, 0.00770125, 0.7739607 ],\n",
       "       [0.07491547, 0.9981222 , 0.98167545],\n",
       "       [0.47962868, 0.989711  , 0.922577  ],\n",
       "       [0.01802978, 0.9891161 , 0.8602406 ]], dtype=float32)>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "temperature = 1e-5\n",
    "\n",
    "scale = 3.\n",
    "softclip = tfb.Chain([tfb.Scale(scale), tfb.Tanh(), tfb.Scale(1. / scale)], name=\"softclip\")\n",
    "minus_log = tfb.Chain([tfb.Scale(-1.), tfb.Log()], name=\"minus_log\")\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    hidden_units=[128, 128],\n",
    "    activation=tfb.Softplus(),\n",
    "    name=\"InvertMaskedAutoregressorNetwork\")\n",
    "\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=tfd.Sample(\n",
    "        tfd.Independent(\n",
    "            distribution=tfd.Logistic(\n",
    "                loc=tf.zeros(shape=event_shape, dtype=tf.float32),\n",
    "                scale=1. / temperature),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    bijector=tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "        lambda y: (\n",
    "            tfb.Chain([tfb.Scale(1. / temperature), softclip])(made(y)[..., 0]),\n",
    "            minus_log(temperature)),\n",
    "        is_constant_jacobian=False)))\n",
    "distribution._made = made\n",
    "\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=distribution,\n",
    "    bijector=tfb.Sigmoid())\n",
    "\n",
    "distribution.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3), dtype=float32, numpy=\n",
       "array([[0.95060885, 0.93537664, 0.7153141 ],\n",
       "       [0.2801799 , 0.9603685 , 0.5810608 ],\n",
       "       [0.14436802, 0.6016128 , 0.24179214],\n",
       "       [0.361446  , 0.5698984 , 0.9822776 ],\n",
       "       [0.7000871 , 0.2468996 , 0.48104683],\n",
       "       [0.95207596, 0.6956586 , 0.71504086],\n",
       "       [0.9911182 , 0.98973346, 0.6715649 ],\n",
       "       [0.2954213 , 0.9990678 , 0.9973613 ]], dtype=float32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "temperature = 1. / 2.\n",
    "\n",
    "scale = 3.\n",
    "softclip = tfb.Chain([tfb.Scale(scale), tfb.Tanh(), tfb.Scale(1. / scale)], name=\"softclip\")\n",
    "minus_log = tfb.Chain([tfb.Scale(-1.), tfb.Log()], name=\"minus_log\")\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    hidden_units=[128, 128],\n",
    "    activation=tfb.Softplus(),\n",
    "    name=\"InvertMaskedAutoregressorNetwork\")\n",
    "\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=tfd.Sample(\n",
    "        tfd.Independent(\n",
    "            distribution=tfd.Logistic(\n",
    "                loc=tf.zeros(shape=event_shape, dtype=tf.float32),\n",
    "                scale=1. / temperature),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    bijector=tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "        lambda y: (\n",
    "            tfb.Chain([tfb.Scale(1. / temperature), softclip])(made(y)[..., 0]),\n",
    "            # minus_log(temperature)),\n",
    "            None),\n",
    "        is_constant_jacobian=True)))\n",
    "distribution._made = made\n",
    "\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=distribution,\n",
    "    bijector=tfb.Sigmoid())\n",
    "\n",
    "distribution.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.512925, shape=(), dtype=float32)\n",
      "tf.Tensor(11.512925, shape=(), dtype=float32)\n",
      "tf.Tensor(11.512925, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9923737, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9923737, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(minus_log(temperature))\n",
    "print(- tf.math.log(temperature))\n",
    "print(tf.math.log(1. / temperature))\n",
    "print(softclip(10.))\n",
    "print(3. * tf.nn.tanh(10. / 3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 3, 2), dtype=float32, numpy=\n",
       "array([[[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.5936074,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.5936074,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.5936074,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.5936074,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.5936074,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.5936074,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.593608 ,  0.       ]],\n",
       "\n",
       "       [[-2.110426 ,  0.       ],\n",
       "        [ 3.2337317,  0.       ],\n",
       "        [ 2.593608 ,  0.       ]]], dtype=float32)>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "cond_shape=(5, )\n",
    "temperature = 1. / 2.\n",
    "\n",
    "scale = 3.\n",
    "softclip = tfb.Chain([tfb.Scale(scale), tfb.Tanh(), tfb.Scale(1. / scale)], name=\"softclip\")\n",
    "\n",
    "x = tfk.Input(shape=event_shape, dtype=tf.float32)\n",
    "y = tfk.Input(shape=cond_shape, dtype=tf.float32)\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    hidden_units=[128, 128],\n",
    "    event_shape=event_shape,\n",
    "    conditional=True,\n",
    "    conditional_event_shape=cond_shape,\n",
    "    activation=tfb.Softplus(),\n",
    "    name=\"InvertMaskedAutoregressorNetwork\")(x, y)\n",
    "\n",
    "made = tfkl.Lambda(\n",
    "    lambda x: tf.stack([\n",
    "        tfb.Chain([tfb.Scale(1. / temperature), softclip])(x[..., 0]),\n",
    "        tf.zeros(tf.shape(x)[:-1])],\n",
    "    axis=-1)\n",
    ")(made)\n",
    "\n",
    "\n",
    "model = tfk.Model(inputs=[x, y], outputs=made)\n",
    "model([tf.zeros((8, ) + event_shape), tf.ones((8, ) + cond_shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Correct one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse masked autoregressive flow without Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 1.]], shape=(8, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "cond_shape=(5, )\n",
    "temperature = 1e-5\n",
    "\n",
    "scale = 3.\n",
    "softclip = tfb.SoftClip(low=-scale, high=scale)\n",
    "\n",
    "class AutoRegressiveLogistic(tf.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AutoRegressiveLogistic, self).__init__()\n",
    "        x = tfk.Input(shape=event_shape, dtype=tf.float32)\n",
    "        y = tfk.Input(shape=cond_shape, dtype=tf.float32)\n",
    "\n",
    "        self._made = tfb.AutoregressiveNetwork(\n",
    "            params=1,\n",
    "            hidden_units=[128, 128],\n",
    "            event_shape=event_shape,\n",
    "            conditional=True,\n",
    "            conditional_event_shape=cond_shape,\n",
    "            activation=tfb.Softplus(),\n",
    "            name=\"InvertMaskedAutoregressorNetwork\")\n",
    "        made = self._made(x, y)\n",
    "        made = tfkl.Lambda(\n",
    "            lambda x: tfb.Chain([tfb.Scale(1. / temperature), softclip])(x[..., 0])\n",
    "        )(made)\n",
    "        self.made = tfk.Model(inputs=[x, y], outputs=made)\n",
    "\n",
    "        \n",
    "    def autoregressive_distribution(self, conditional):\n",
    "        batch_size = tf.shape(conditional)[0]\n",
    "        distribution = tfd.TransformedDistribution(\n",
    "        distribution=tfd.Sample(\n",
    "            tfd.Independent(\n",
    "                distribution=tfd.Logistic(\n",
    "                    loc=tf.zeros(shape=(batch_size, ) + event_shape, dtype=tf.float32),\n",
    "                    scale=1. / temperature),\n",
    "                reinterpreted_batch_ndims=1)),\n",
    "        bijector=tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "            lambda x: (self.made([x, conditional]), None),\n",
    "            is_constant_jacobian=False)))\n",
    "\n",
    "        return tfd.TransformedDistribution(\n",
    "            distribution=distribution,\n",
    "            bijector=tfb.Sigmoid())\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self, conditional):\n",
    "        return self.autoregressive_distribution(conditional).sample()\n",
    "\n",
    "\n",
    "x = AutoRegressiveLogistic()(tf.ones((8, ) + cond_shape))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 1.]\n",
      " [0. 1. 0.]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[458.6469  322.86954 458.6469  458.6469  384.77975 458.6469  458.6469\n",
      " 458.6469 ], shape=(8,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[458.6469  384.85165 384.85165 384.77975 384.77975 384.77975 322.86954\n",
      " 384.85165], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "d = AutoRegressiveLogistic().autoregressive_distribution(tf.ones((8, ) + cond_shape))\n",
    "distribution = tfd.TransformedDistribution(\n",
    "    distribution=d,\n",
    "    bijector=tfb.Inline(\n",
    "        forward_fn=tf.round,\n",
    "        inverse_fn=tfb.Identity,\n",
    "        forward_min_event_ndims=0,\n",
    "        inverse_min_event_ndims=0))\n",
    "\n",
    "\n",
    "print(distribution.sample())\n",
    "print(d.prob(tf.clip_by_value(tf.abs(distribution.sample() - 1.), clip_value_min=1e-7, clip_value_max=1. - 1e-7)))\n",
    "print(d.prob(tf.clip_by_value(tf.round(x), clip_value_min=1e-7, clip_value_max=1. - 1e-7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "cond_shape=(5, )\n",
    "temperature = 0.5\n",
    "\n",
    "scale = 3.\n",
    "softclip = tfb.SoftClip(low=-scale, high=scale)\n",
    "\n",
    "class AutoRegressiveBernoulli(tfk.Model):\n",
    "    \n",
    "    def __init__(self, event_shape, cond_shape=None):\n",
    "        \n",
    "        x = tfk.Input(shape=event_shape, dtype=tf.float32)\n",
    "        if cond_shape is not None:\n",
    "            y = tfk.Input(shape=cond_shape, dtype=tf.float32)\n",
    "        else:\n",
    "            y = None\n",
    "        \n",
    "        _made = tfb.AutoregressiveNetwork(\n",
    "            params=1,\n",
    "            hidden_units=[128, 128],\n",
    "            event_shape=event_shape,\n",
    "            conditional=cond_shape is not None,\n",
    "            conditional_event_shape=cond_shape,\n",
    "            activation=tfb.Softplus())\n",
    "        made = _made(x, conditional_input=y)\n",
    "        made = tfkl.Lambda(\n",
    "            lambda x: softclip(x[..., 0])\n",
    "        )(made)\n",
    "        \n",
    "        super(AutoRegressiveBernoulli, self).__init__(inputs=x if y is None else [x, y], outputs=made)\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_made_inputs(x, conditional = None, *args, **kwargs):\n",
    "        return [x, conditional] if conditional is not None else x\n",
    "\n",
    "    def relaxed_distribution(self, temperature, conditional=None):\n",
    "\n",
    "        def distribution_fn(x=None):\n",
    "            if x is None:\n",
    "                return tfd.Independent(\n",
    "                    distribution=tfd.TransformedDistribution(\n",
    "                        distribution=tfd.Logistic(\n",
    "                            loc=tf.zeros(shape=event_shape, dtype=tf.float32),\n",
    "                            scale=1. / temperature),\n",
    "                        bijector=tfb.Sigmoid()),\n",
    "                    reinterpreted_batch_ndims=1)\n",
    "            else:\n",
    "                inputs = self._process_made_inputs(x, conditional)\n",
    "                return tfd.Independent(\n",
    "                    distribution=tfd.TransformedDistribution(\n",
    "                        distribution=tfd.Logistic(\n",
    "                            loc=self(inputs) / temperature,\n",
    "                            scale=1. / temperature),\n",
    "                        bijector=tfb.Sigmoid()),\n",
    "                    reinterpreted_batch_ndims=1)\n",
    "\n",
    "\n",
    "        print(distribution_fn().event_shape)\n",
    "        return tfd.Autoregressive(distribution_fn)\n",
    "    \n",
    "    def discrete_distribution(self, conditional=None):\n",
    "        \n",
    "        def distribution_fn(x=None):\n",
    "            if x is None:\n",
    "                return tfd.Independent(\n",
    "                    distribution=tfd.Bernoulli(logits=tf.zeros(event_shape)),\n",
    "                    reinterpreted_batch_ndims=1)\n",
    "            else:\n",
    "                inputs = self._process_made_inputs(x, conditional)\n",
    "                return tfd.Independent(\n",
    "                    distribution=tfd.Bernoulli(logits=self(inputs)),\n",
    "                    reinterpreted_batch_ndims=1)\n",
    "        \n",
    "        return tfd.Autoregressive(distribution_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 0.]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[1.0413770e+10 1.0413770e+10 3.7047258e+09 3.7047258e+09 1.1448654e+09\n",
      " 3.3035971e+09 3.2323855e+09 3.2323855e+09], shape=(8,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]\n",
      " [1 0 0]], shape=(8, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[0.20455365 0.20455365 0.11671299 0.11671299 0.06483471 0.11513042\n",
      " 0.11348242 0.11348242], shape=(8,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.49189883, 0.22471553, 0.9895641 ], dtype=float32)>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_shape=(3, )\n",
    "\n",
    "autoregressive_model = AutoRegressiveBernoulli(event_shape=event_shape)\n",
    "distribution = autoregressive_model.relaxed_distribution(temperature=.5)\n",
    "x = tf.round(distribution.sample(8))\n",
    "print(x)\n",
    "print(distribution.prob(tf.clip_by_value(x, clip_value_min=1e-7, clip_value_max=1.-1e-7)))\n",
    "discrete_distribution = autoregressive_model.discrete_distribution()\n",
    "print(discrete_distribution.sample(8))\n",
    "print(discrete_distribution.prob(x))\n",
    "autoregressive_model.relaxed_distribution(temperature=.5).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "tf.Tensor(\n",
      "[[1. 0. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 1.]], shape=(8, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[1.2603643e+10 2.7974690e+11 2.7974690e+11 2.7974690e+11 3.1810054e+10\n",
      " 2.7974690e+11 3.1810054e+10 2.7974690e+11], shape=(8,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 0 0]\n",
      " [1 1 1]\n",
      " [1 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]], shape=(8, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[0.10981445 0.5398283  0.5398283  0.5398283  0.17404315 0.5398283\n",
      " 0.17404312 0.53982824], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "event_shape=(3, )\n",
    "cond_shape=(5, )\n",
    "batch_size = 8\n",
    "\n",
    "autoregressive_model = AutoRegressiveBernoulli(event_shape=event_shape, cond_shape=cond_shape)\n",
    "conditional_samples = tf.ones((batch_size, ) + cond_shape)\n",
    "distribution = autoregressive_model.relaxed_distribution(temperature=.5, conditional=conditional_samples)\n",
    "x = tf.round(distribution.sample(batch_size))  # works only with sample(batch_size)\n",
    "print(x)\n",
    "print(distribution.prob(tf.clip_by_value(x, clip_value_min=1e-7, clip_value_max=1.-1e-7)))\n",
    "discrete_distribution = autoregressive_model.discrete_distribution(conditional=conditional_samples)\n",
    "print(discrete_distribution.sample(batch_size))\n",
    "print(discrete_distribution.prob(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked autoregressive flow for generating relaxed Bernoulli (via bijector_fn instead of shift_and_log_scale_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 18:05:04.137086: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "batch_size=8\n",
    "event_shape=(3, )\n",
    "cond_shape=(5, )\n",
    "temperature = 0.5\n",
    "\n",
    "scale = 3.\n",
    "softclip = tfb.SoftClip(low=-scale, high=scale)\n",
    "\n",
    "class MaskedAutoRegressiveBernoulli(tfk.Model):\n",
    "    \n",
    "    def __init__(self, event_shape, cond_shape=None):\n",
    "        \n",
    "        x = tfk.Input(shape=event_shape, dtype=tf.float32)\n",
    "        if cond_shape is not None:\n",
    "            y = tfk.Input(shape=cond_shape, dtype=tf.float32)\n",
    "        else:\n",
    "            y = None\n",
    "        \n",
    "        _made = tfb.AutoregressiveNetwork(\n",
    "            params=1,\n",
    "            hidden_units=[128, 128],\n",
    "            event_shape=event_shape,\n",
    "            conditional=cond_shape is not None,\n",
    "            conditional_event_shape=cond_shape,\n",
    "            activation=tfb.Softplus())\n",
    "        made = _made(x, conditional_input=y)\n",
    "        made = tfkl.Lambda(\n",
    "            lambda x: softclip(x[..., 0])\n",
    "        )(made)\n",
    "        \n",
    "        super(MaskedAutoRegressiveBernoulli, self).__init__(inputs=x if y is None else [x, y], outputs=made)\n",
    "        self.event_shape = event_shape\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_made_inputs(x, conditional = None, *args, **kwargs):\n",
    "        return [x, conditional] if conditional is not None else x\n",
    "\n",
    "    def relaxed_distribution(self, temperature, conditional=None):\n",
    "        \n",
    "        def bijector_fn(x) -> tfb.Bijector:\n",
    "            inputs = self._process_made_inputs(x, conditional)\n",
    "            shift = self(inputs) / temperature\n",
    "            return tfb.Chain([tfb.Sigmoid(), tfb.Shift(shift)])\n",
    "        \n",
    "        return tfd.TransformedDistribution(\n",
    "            distribution=tfd.Sample(\n",
    "                tfd.Logistic(loc=0., scale=1. / temperature), sample_shape=self.event_shape),\n",
    "            bijector=tfb.MaskedAutoregressiveFlow(bijector_fn=bijector_fn))\n",
    "    \n",
    "    def discrete_distribution(self, conditional=None):\n",
    "        \n",
    "        def distribution_fn(x=None):\n",
    "            if x is None:\n",
    "                logits = tf.zeros(event_shape)\n",
    "            else:\n",
    "                inputs = self._process_made_inputs(x, conditional)\n",
    "                logits = self(inputs)\n",
    "                \n",
    "            return tfd.Independent(\n",
    "                distribution=tfd.Bernoulli(logits=logits),\n",
    "                reinterpreted_batch_ndims=1)\n",
    "\n",
    "        return tfd.Autoregressive(distribution_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rounded relaxed sample tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
      "logistic prob with clipped sample tf.Tensor(2416530000.0, shape=(), dtype=float32)\n",
      "discrete sample tf.Tensor([0 0 1], shape=(3,), dtype=int32)\n",
      "discrete prob tf.Tensor(0.09348528, shape=(), dtype=float32)\n",
      "relaxed sample tf.Tensor([9.9999845e-01 9.9999738e-01 2.2329972e-15], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "event_shape=(3, )\n",
    "batch_size = 2\n",
    "\n",
    "autoregressive_model = MaskedAutoRegressiveBernoulli(event_shape=event_shape)\n",
    "distribution = autoregressive_model.relaxed_distribution(temperature=.5)\n",
    "x = tf.round(distribution.sample())\n",
    "print(\"rounded relaxed sample\", x)\n",
    "print(\"logistic prob with clipped sample\",\n",
    "      distribution.prob(tf.clip_by_value(x, clip_value_min=1e-7, clip_value_max=1.-1e-7)))\n",
    "discrete_distribution = autoregressive_model.discrete_distribution()\n",
    "print(\"discrete sample\", discrete_distribution.sample())\n",
    "print(\"discrete prob\", discrete_distribution.prob(x))\n",
    "print(\"relaxed sample\", autoregressive_model.relaxed_distribution(temperature=.1).sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional samples tf.Tensor(\n",
      "[[0.28799808 0.9021977  0.7689476  0.07662714 0.27008283]\n",
      " [0.11628854 0.22444272 0.30513394 0.14792514 0.4099145 ]\n",
      " [0.36682987 0.07588935 0.4018519  0.79595053 0.877362  ]\n",
      " [0.4473132  0.47209036 0.7915766  0.5921581  0.81145406]], shape=(4, 5), dtype=float32)\n",
      "rounded relaxed sample tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(4, 3), dtype=float32)\n",
      "logistic prob with clipped sample tf.Tensor([14563.715 14587.958 11862.641 11656.918], shape=(4,), dtype=float32)\n",
      "discrete sample tf.Tensor(\n",
      "[[0 1 0]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 1 0]], shape=(4, 3), dtype=int32)\n",
      "discrete prob tf.Tensor([0.16888657 0.17486104 0.16713713 0.17505668], shape=(4,), dtype=float32)\n",
      "relaxed sample tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "event_shape=(3, )\n",
    "cond_shape=(5, )\n",
    "batch_size = 4\n",
    "temperature = 1e-5\n",
    "\n",
    "\n",
    "autoregressive_model = MaskedAutoRegressiveBernoulli(event_shape=event_shape, cond_shape=cond_shape)\n",
    "conditional_samples = tf.random.uniform((batch_size, ) + cond_shape)\n",
    "print(\"conditional samples\", conditional_samples)\n",
    "distribution = autoregressive_model.relaxed_distribution(\n",
    "    temperature=temperature, conditional=conditional_samples)\n",
    "x = tf.round(distribution.sample())\n",
    "print(\"rounded relaxed sample\", x)\n",
    "print(\"logistic prob with clipped sample\",\n",
    "      distribution.prob(tf.clip_by_value(x, clip_value_min=1e-7, clip_value_max=1.-1e-7)))\n",
    "discrete_distribution = autoregressive_model.discrete_distribution(conditional=conditional_samples)\n",
    "# Important: to sample from the discrete distribution, we need\n",
    "# provide the batch size of the sample manually so that it matches the batch size of the conditional event\n",
    "print(\"discrete sample\", discrete_distribution.sample(batch_size))\n",
    "print(\"discrete prob\", discrete_distribution.prob(x))\n",
    "print(\"relaxed sample\", \n",
    "      autoregressive_model.relaxed_distribution(\n",
    "          temperature=temperature, conditional=conditional_samples\n",
    "      ).sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoregressiveNetwork' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/03/wm8m8y9d50b1rxl0lpvj0dn40000gn/T/ipykernel_33898/1029860312.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoregressive_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoregressiveNetwork' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "autoregressive_model.layers[2].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64]\n",
      "<function <lambda> at 0x7f894bf1add0>\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = []\n",
    "activation = None\n",
    "for layer in _model.layers:\n",
    "    hidden_layers.append(layer.units)\n",
    "    if activation != layer.activation:\n",
    "        activation = layer.activation\n",
    "    \n",
    "print(hidden_layers)\n",
    "print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5249792 , 0.549834  , 0.59868765, 0.6224593 ], dtype=float32)>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfb.Sigmoid()([0.1, 0.2, 0.4, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.5249792 , 0.549834  , 0.59868765, 0.6224593 ], dtype=float32)>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.sigmoid([0.1, 0.2, 0.4, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.60080117>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd.Independent(\n",
    "    tfd.RelaxedBernoulli(logits=[0.1, 0.2, 0.4, 0.5], temperature=1./2.),\n",
    "    reinterpreted_batch_ndims=1\n",
    ").prob([0.5, 0.9, 0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.60080075>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd.Independent(\n",
    "    tfd.TransformedDistribution(\n",
    "        distribution=tfd.Logistic(loc=tf.constant([0.1, 0.2, 0.4, 0.5]) / 0.5, scale=2.),\n",
    "        bijector=tfb.Sigmoid()),\n",
    "    reinterpreted_batch_ndims=1,\n",
    ").prob([0.5, 0.9, 0.1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.8827684 , 0.9125265 , 0.9985579 , 0.06163964, 1.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd.Blockwise([\n",
    "    tfd.Independent(\n",
    "        tfd.TransformedDistribution(\n",
    "            distribution=tfd.Logistic(loc=tf.constant([0.1, 0.2, 0.4, 0.5]) / 0.5, scale=2.),\n",
    "            bijector=tfb.Sigmoid()),\n",
    "        reinterpreted_batch_ndims=1,\n",
    "    ),\n",
    "    tfd.Bernoulli(logits=10., dtype=tf.float32)\n",
    "]).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_109'), name='input_109', description=\"created by layer 'input_109'\"), but it was called on an input with incompatible shape (1, None, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_109'), name='input_109', description=\"created by layer 'input_109'\"), but it was called on an input with incompatible shape (1, None, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name='input_109'), name='input_109', description=\"created by layer 'input_109'\"), but it was called on an input with incompatible shape (1, None, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nThe following Variables were created within a Lambda layer (distribution_lambda_20)\nbut are not tracked by said layer:\n  <tf.Variable 'dense/kernel:0' shape=(3, 64) dtype=float32>\n  <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32>\n  <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32>\n  <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32>\n  <tf.Variable 'dense_2/kernel:0' shape=(64, 3) dtype=float32>\n  <tf.Variable 'dense_2/bias:0' shape=(3,) dtype=float32>\n  <tf.Variable 'distribution_lambda_20/Autoregressive/autoregressive_network_64/Variable:0' shape=() dtype=int64>\n  <tf.Variable 'distribution_lambda_20/Autoregressive/autoregressive_network_64/Variable:0' shape=() dtype=int64>\n  <tf.Variable 'distribution_lambda_20/Autoregressive/autoregressive_network_64/Variable:0' shape=() dtype=int64>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consquently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-d423b9e3b04d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtfkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtfpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributionLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_distribution_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m ])\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow_probability/python/layers/distribution_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_dunder_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     distribution, _ = super(DistributionLambda, self).__call__(\n\u001b[0;32m--> 246\u001b[0;31m         inputs, *args, **kwargs)\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enter_dunder_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow_probability/python/layers/distribution_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     distribution, value = super(DistributionLambda, self).call(\n\u001b[0;32m--> 252\u001b[0;31m         inputs, *args, **kwargs)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;31m# We always save the most recently built distribution for variable tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;31m# purposes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreated_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/vae_mdp/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_check_variables\u001b[0;34m(self, created_variables, accessed_variables)\u001b[0m\n\u001b[1;32m    943\u001b[0m           Variables.'''\n\u001b[1;32m    944\u001b[0m       ).format(name=self.name, variable_str=variable_str)\n\u001b[0;32m--> 945\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     untracked_used_vars = [\n",
      "\u001b[0;31mValueError\u001b[0m: \nThe following Variables were created within a Lambda layer (distribution_lambda_20)\nbut are not tracked by said layer:\n  <tf.Variable 'dense/kernel:0' shape=(3, 64) dtype=float32>\n  <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32>\n  <tf.Variable 'dense_1/kernel:0' shape=(64, 64) dtype=float32>\n  <tf.Variable 'dense_1/bias:0' shape=(64,) dtype=float32>\n  <tf.Variable 'dense_2/kernel:0' shape=(64, 3) dtype=float32>\n  <tf.Variable 'dense_2/bias:0' shape=(3,) dtype=float32>\n  <tf.Variable 'distribution_lambda_20/Autoregressive/autoregressive_network_64/Variable:0' shape=() dtype=int64>\n  <tf.Variable 'distribution_lambda_20/Autoregressive/autoregressive_network_64/Variable:0' shape=() dtype=int64>\n  <tf.Variable 'distribution_lambda_20/Autoregressive/autoregressive_network_64/Variable:0' shape=() dtype=int64>\nThe layer cannot safely ensure proper Variable reuse across multiple\ncalls, and consquently this behavior is disallowed for safety. Lambda\nlayers are not well suited to stateful computation; instead, writing a\nsubclassed Layer is the recommend way to define layers with\nVariables."
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "event_shape = (3, )\n",
    "\n",
    "autoregressor = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    event_shape=event_shape,\n",
    "    hidden_units=[64, 64],\n",
    "    activation='relu')\n",
    "\n",
    "\n",
    "def distribution(x):    \n",
    "    return tfd.Autoregressive(\n",
    "        lambda y: tfd.Independent(\n",
    "            tfd.TransformedDistribution(\n",
    "                distribution=tfd.Logistic(\n",
    "                    loc=tf.unstack(autoregressor(y), axis=-1)[0] / 0.5,\n",
    "                    scale=2.),\n",
    "                bijector=tfb.Sigmoid()),\n",
    "            reinterpreted_batch_ndims=1),\n",
    "        sample0=x)\n",
    "\n",
    "model = tfk.Sequential([\n",
    "    tfk.Input(shape=event_shape),\n",
    "    tfkl.Dense(units=np.prod(event_shape), activation='relu'),\n",
    "    tfpl.DistributionLambda(make_distribution_fn=distribution)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss= lambda y, model: -model.log_prob(y))\n",
    "                     \n",
    "model.fit(\n",
    "    x=tf.zeros(shape=(dataset_size,), dtype=tf.float32),  # always provide the same input\n",
    "    y=dataset,\n",
    "    batch_size=batch_size,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=dataset_size // batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=True)\n",
    "\n",
    "bernoulli = distribution(tf.zeros(1, 3, dtype=tf.float32))\n",
    "tf.print(\"P(s_1 | s_0) =\", distribution.prob(states[1]))\n",
    "tf.print(\"P(s_2 | s_0) =\", distribution.prob(states[2]))\n",
    "tf.print(\"P(s_3 | s_0) =\", distribution.prob(states[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'event_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-307-f771aeecc78b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msample0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mevent_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     validate_args=True)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'event_shape'"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "event_shape = (3, )\n",
    "\n",
    "autoregressor = tfb.AutoregressiveNetwork(\n",
    "    params=1,\n",
    "    event_shape=event_shape,\n",
    "    hidden_units=[64, 64],\n",
    "    activation='relu')\n",
    "\n",
    "distribution = tfd.Autoregressive(\n",
    "    lambda x: tfd.Independent(\n",
    "        tfd.RelaxedBernoulli(\n",
    "            logits=tf.unstack(autoregressor(x), axis=-1)[0],\n",
    "            temperature=1./2.),\n",
    "        reinterpreted_batch_ndims=1),\n",
    "    sample0=tf.zeros(shape=(batch_size,) + event_shape),\n",
    "    validate_args=True)\n",
    "\n",
    "x = tfk.Input(shape=event_shape)\n",
    "log_prob = distribution.log_prob(x)\n",
    "model = tfk.Model(x, log_prob)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=1e-2),\n",
    "    loss= lambda _, log_prob: -log_prob)\n",
    "\n",
    "model.fit(\n",
    "    x=dataset,\n",
    "    y=tf.zeros(shape=(dataset_size, )), # log_prob = 0 <=> prob = 1\n",
    "    batch_size=batch_size,\n",
    "    epochs=4,\n",
    "    steps_per_epoch=dataset_size // batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=True)\n",
    "\n",
    "bernoulli = distribution\n",
    "tf.print(\"P(s_1 | s_0) =\", distribution.prob(states[1]))\n",
    "tf.print(\"P(s_2 | s_0) =\", distribution.prob(states[2]))\n",
    "tf.print(\"P(s_3 | s_0) =\", distribution.prob(states[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12, 8, 3), dtype=float32, numpy=\n",
       "array([[[3.79536152e-02, 2.71249473e-01, 8.78530264e-01],\n",
       "        [6.35766685e-01, 8.96939754e-01, 9.45525587e-01],\n",
       "        [7.10226595e-02, 3.24407458e-01, 6.88435137e-01],\n",
       "        [4.26471233e-04, 9.17298079e-01, 1.70042813e-02],\n",
       "        [6.73601031e-03, 1.08616352e-02, 7.72562146e-01],\n",
       "        [6.22768402e-01, 5.70048451e-01, 9.32394862e-01],\n",
       "        [1.93144381e-02, 9.84224319e-01, 2.31177509e-02],\n",
       "        [4.43371236e-02, 4.78261411e-02, 1.75740272e-01]],\n",
       "\n",
       "       [[8.53002369e-02, 9.80932474e-01, 2.81270206e-01],\n",
       "        [2.99131423e-01, 1.40638530e-01, 3.35832477e-01],\n",
       "        [4.45834994e-02, 2.84981728e-02, 4.51387763e-02],\n",
       "        [2.01447934e-01, 9.64342475e-01, 5.64982355e-01],\n",
       "        [8.25147331e-01, 5.42085230e-01, 9.80766177e-01],\n",
       "        [6.86310828e-01, 9.99991894e-01, 9.98379588e-01],\n",
       "        [1.03266448e-01, 4.05542761e-01, 6.59287333e-01],\n",
       "        [9.17372108e-01, 9.98853326e-01, 3.90919894e-01]],\n",
       "\n",
       "       [[9.12598610e-01, 9.67505872e-01, 1.44243240e-04],\n",
       "        [3.10213864e-02, 2.17034817e-02, 1.96767062e-01],\n",
       "        [8.12489986e-02, 2.11820900e-01, 3.56763154e-01],\n",
       "        [8.02622795e-01, 8.61808777e-01, 9.99189198e-01],\n",
       "        [8.97864163e-01, 6.15090132e-04, 8.54526460e-02],\n",
       "        [7.30417013e-01, 9.12958264e-01, 1.53276324e-02],\n",
       "        [5.39383292e-03, 9.29220796e-01, 2.81170905e-02],\n",
       "        [9.98277903e-01, 8.87674868e-01, 3.60551476e-03]],\n",
       "\n",
       "       [[8.72272730e-01, 8.97776246e-01, 9.72183645e-02],\n",
       "        [6.23987198e-01, 7.99578428e-02, 1.03234415e-05],\n",
       "        [9.72054601e-01, 7.49398708e-01, 1.37267411e-02],\n",
       "        [8.50594401e-01, 9.75176692e-03, 1.12121403e-02],\n",
       "        [1.09389722e-01, 3.28299403e-02, 9.97847378e-01],\n",
       "        [6.95419312e-02, 2.79951423e-01, 4.59835947e-01],\n",
       "        [9.27136242e-01, 9.83108580e-01, 9.23810124e-01],\n",
       "        [9.88146305e-01, 9.38685775e-01, 3.38161226e-05]],\n",
       "\n",
       "       [[3.65823269e-01, 2.84957945e-01, 6.06089830e-04],\n",
       "        [9.13128257e-01, 8.17742050e-01, 2.66714394e-02],\n",
       "        [3.16956639e-02, 8.21008384e-02, 9.95672762e-01],\n",
       "        [9.99668241e-01, 2.91604519e-01, 5.46568930e-01],\n",
       "        [9.94413376e-01, 7.62909353e-02, 8.99228454e-02],\n",
       "        [3.53029430e-01, 5.37496805e-03, 4.21517879e-01],\n",
       "        [4.19598222e-02, 4.68564838e-01, 6.11524820e-01],\n",
       "        [8.69549870e-01, 7.66351104e-01, 5.38756430e-01]],\n",
       "\n",
       "       [[9.67192471e-01, 9.02180552e-01, 9.30653930e-01],\n",
       "        [2.76997685e-03, 2.78057337e-01, 7.24854052e-01],\n",
       "        [9.96507764e-01, 5.79226613e-01, 1.02109671e-01],\n",
       "        [1.14807636e-01, 9.99961972e-01, 7.35772848e-02],\n",
       "        [9.99999166e-01, 8.97573531e-02, 6.24266267e-03],\n",
       "        [7.92253911e-01, 7.80566037e-01, 8.80243540e-01],\n",
       "        [7.10952163e-01, 9.70643878e-01, 9.98337030e-01],\n",
       "        [9.46377158e-01, 2.87390947e-02, 3.95618528e-01]],\n",
       "\n",
       "       [[7.41252780e-01, 8.28906894e-03, 6.42109811e-01],\n",
       "        [5.93034923e-01, 9.81404781e-01, 1.56445742e-01],\n",
       "        [6.98769093e-01, 3.74115705e-01, 2.64541864e-01],\n",
       "        [1.24938548e-01, 8.52703273e-01, 2.67822146e-02],\n",
       "        [6.32028759e-01, 9.08968210e-01, 5.65043569e-01],\n",
       "        [2.26762235e-01, 1.41120553e-02, 2.40972608e-01],\n",
       "        [9.70221698e-01, 5.57341218e-01, 9.37250793e-01],\n",
       "        [7.47940302e-01, 1.75744802e-01, 3.10363352e-01]],\n",
       "\n",
       "       [[4.89371300e-01, 4.40774143e-01, 7.56802380e-01],\n",
       "        [2.62886107e-01, 3.68360341e-01, 1.03904754e-01],\n",
       "        [8.23322237e-01, 9.56766009e-02, 1.99169070e-01],\n",
       "        [1.27141118e-01, 7.98732042e-03, 1.00000000e+00],\n",
       "        [8.95082057e-02, 1.65441930e-02, 5.06967306e-04],\n",
       "        [8.34850192e-01, 6.25193119e-04, 3.16957235e-02],\n",
       "        [3.03008437e-01, 1.02474809e-01, 2.58621335e-01],\n",
       "        [9.41627026e-01, 2.15447634e-01, 9.26031291e-01]],\n",
       "\n",
       "       [[9.79486585e-01, 6.36328459e-02, 3.06694567e-01],\n",
       "        [7.02018440e-02, 8.19990396e-01, 9.90953445e-01],\n",
       "        [9.13963437e-01, 9.72976148e-01, 7.87613511e-01],\n",
       "        [7.62232542e-01, 9.16451693e-01, 3.98435771e-01],\n",
       "        [4.65755433e-01, 7.24047422e-04, 3.36305261e-01],\n",
       "        [1.10265017e-01, 9.74489987e-01, 9.85858798e-01],\n",
       "        [1.97105616e-01, 8.90075207e-01, 9.93474364e-01],\n",
       "        [8.56449723e-01, 9.65870082e-01, 6.50449097e-02]],\n",
       "\n",
       "       [[6.32476628e-01, 2.25059569e-01, 2.57205129e-01],\n",
       "        [3.24877203e-02, 2.81530023e-02, 1.07684433e-02],\n",
       "        [4.62715328e-02, 4.10031438e-01, 8.13045263e-01],\n",
       "        [5.14526844e-01, 9.94072497e-01, 5.46352625e-01],\n",
       "        [7.73717403e-01, 9.75285172e-01, 9.92175698e-01],\n",
       "        [1.89243853e-02, 7.52042890e-01, 5.02453804e-01],\n",
       "        [4.03756440e-01, 1.27628416e-01, 2.90711850e-01],\n",
       "        [9.98234868e-01, 9.88454461e-01, 5.61964571e-01]],\n",
       "\n",
       "       [[7.92363524e-01, 2.53149658e-01, 4.70450521e-01],\n",
       "        [4.12796170e-01, 4.60659802e-01, 9.61035252e-01],\n",
       "        [8.06051075e-01, 2.67127335e-01, 1.61570400e-01],\n",
       "        [9.60894346e-01, 3.10455441e-01, 6.63556039e-01],\n",
       "        [5.97038865e-03, 2.19961703e-02, 1.49728656e-01],\n",
       "        [9.54902530e-01, 2.37067342e-02, 6.85238838e-03],\n",
       "        [3.73851776e-01, 8.45883906e-01, 9.02188897e-01],\n",
       "        [6.43521249e-02, 7.10785568e-01, 4.44734782e-01]],\n",
       "\n",
       "       [[8.78752768e-02, 6.27851248e-01, 4.58721340e-01],\n",
       "        [9.44911957e-01, 4.11090255e-03, 2.38469243e-03],\n",
       "        [9.99693573e-01, 1.91183090e-02, 9.99844909e-01],\n",
       "        [9.23060656e-01, 4.96996313e-01, 9.17676747e-01],\n",
       "        [1.86125636e-02, 9.90598202e-01, 5.72402656e-01],\n",
       "        [7.96912193e-01, 9.88193572e-01, 9.23091769e-02],\n",
       "        [8.90359282e-03, 2.36742854e-01, 7.53009677e-01],\n",
       "        [8.87038887e-01, 3.19482327e-01, 6.14842772e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution.sample(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_184 (Dense)            (8, 3)                    6         \n",
      "_________________________________________________________________\n",
      "distribution_lambda_19 (Dist multiple                  0         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_state = tfk.Input(shape=(17,))\n",
    "latent_action = tfk.Input(shape=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(2,) dtype=int32 inferred_value=[None, None] (created by layer 'tf.__operators__.add_50')>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(latent_state) + tf.shape(latent_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfkl.Concatenate()([latent_state, latent_action]).shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.0'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
